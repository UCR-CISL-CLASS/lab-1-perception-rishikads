[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/w3FoW0fO)
# EE260C_LAB1: Perception

Please refer to the instructions [here](https://docs.google.com/document/d/1BvQ9ztEvxDwsHv-RWEy2EOA7kdAonzdkbJIuQSB1nJI/edit?usp=sharing)

This lab focuses on implementing a perception module for detecting 3D groundtruth bounding boxes around traffic participants in CARLA using multi-modal sensors.

Part 1
Step 1- Launch carla server.
Step 2- Generating traffic.
Step 3- Run automatic_control.py (The vehicle crashes everywhere and "Total object instances: x, The Average Precision at IOU x is 0.00" is obtained).

Part 2
Step 4- Added 4 sensors- RBG left, RGB right, RGB centre and lidar
Step 5- Visualize every sensor by pressing TAB and take SS.
Step 6- Visualize the groundtruth bounding boxes of the traffic participants.

Part 3
Step 7- Implement faster CNN detection model.
Step 8- Visualize the output using the detection model.
